# code/embedding_utils.py

"""
This code is designed to create a ChromaDB collection by embedding text documents and enabling efficient document retrieval through semantic search. 
It uses embeddings generated by Ollama to add documents to a database if they do not already exist and allows searching for relevant documents based on a given query. 
The example is related to cellxgene collections.

Core Idea:
The core concept behind this code is the use of document embeddings to represent text documents in a high-dimensional vector space. 
By doing so, the system can store these vectors in a collection and perform semantic searches. 
This means instead of searching for exact text matches, the system searches for documents that are semantically similar to the query by comparing their embeddings. 
This allows for more intelligent document retrieval.

The workflow involves:

	1.	Checking if a document already exists in the database.
	2.	If not, computing the document’s embedding and storing it in ChromaDB.
	3.	Using embeddings to find the most relevant documents when queried.

Sources:

	•	ollama: A library for generating text embeddings.
	•	chromadb: A library that serves as a database for storing embeddings and allows for vector-based document retrieval.
	•	tqdm: A library for creating progress bars, used to display the progress of document processing.
	•	pandas: A data manipulation library, used here to read collections data from a parquet file.
	•	Custom Utility Functions (ollama_utils):
	•	get_embedding: Function to retrieve document embeddings.
	•	restart_ollama_server: A function to restart the Ollama server, ensuring it is running for embedding generation.

Code Walkthrough:

	1.	Document Existence Check (document_exists):
	•	This function checks if a document already exists in the collection using the $contains operator, which searches for an exact match of the document text.
	2.	Adding Document Embedding (add_document):
	•	This function first checks if the document already exists (to avoid duplication). If not, it generates an embedding for the document and adds it to the collection, along with a unique ID.
	3.	Processing Documents (process_documents):
	•	This function processes a list of documents, generating and adding embeddings for each document into a collection (via add_document), while displaying the progress using tqdm.
	4.	Main Block:
	•	The Ollama server is restarted to ensure it’s ready for embedding generation.
	•	A parquet file containing metadata about cellxgene collections is loaded using pandas. This file contains descriptions of collections that are converted into a list of documents.
	•	A persistent ChromaDB client is created, which interacts with a collection stored on disk.
	•	Documents are processed, and embeddings are added to the “descriptions” collection.
	5.	Querying the Collection:
	•	The collection is queried using a custom search string (e.g., "colon crohn"), and the embeddings for this query are compared with the stored embeddings to find the top 5 most similar documents based on distance.

How to Use:


	1.	Ensure you have the necessary parquet file at /data/collections/cellxgene_collections_metadata.parquet containing the descriptions for the documents.
	•	Ensure the Ollama server is running and accessible.
	•	Make sure that chromadb is installed and configured correctly, as it will store the collection.
	2.	Add Documents:
	•	To add documents to the collection, simply run the script. This will process the description field from the parquet file and add embeddings to a ChromaDB collection named "descriptions".
	3.	Query the Collection:
	•	After documents are added, you can query the collection by embedding your search string (e.g., "colon crohn") and retrieving the most relevant documents based on their similarity to the query.
"""


import chromadb
from tqdm import tqdm
from ollama_utils import get_embedding, restart_ollama_server
import pandas as pd


def document_exists(collection, doc):
    """Check if the exact document text already exists in the collection."""
    # Use the $contains operator to search for the exact text in the collection
    existing_docs = collection.get(
        where_document={"$contains": doc},  # Pass the document string directly
        include=["documents"],
    )

    # If the document is found, return True
    return len(existing_docs["documents"]) > 0


def add_document(collection, doc, doc_id):
    """Add document embedding to the collection if the document doesn't exist."""
    if document_exists(collection, doc):
        return

    embedding = get_embedding(doc)
    collection.add(
        ids=[str(doc_id)],
        embeddings=[embedding[0]], 
        documents=[doc],
    )


def process_documents(client, docs, collection_name):
    """Process the list of documents and add embeddings."""
    collection = client.get_or_create_collection(name=collection_name)
    for i, doc in enumerate(tqdm(docs)):
        add_document(collection, doc, i)


def initialize_rag_database():
    collections = pd.read_parquet("/data/collections/cellxgene_collections_metadata.parquet")
    docs = collections.description.tolist()
    client = chromadb.PersistentClient(path="/scratch/cellxgene_collections_chromadb")
    process_documents(client, docs, collection_name="descriptions")
    return client



if __name__ == "__main__":
    restart_ollama_server()
    # --------------------
    # how to create a collection and embeddign database ...
    collections = pd.read_parquet("/data/collections/cellxgene_collections_metadata.parquet")
    client = initialize_rag_database()

    # --------------------
    # How to use this collection:
    collection =client.get_collection(name="descriptions")
    query = "colon crohn"

    # Search for the most relevant document
    results = collection.query(
        query_embeddings=[get_embedding(query)[0]],
        n_results=5,
        include=["documents", "distances"]
    )
    print(results)
